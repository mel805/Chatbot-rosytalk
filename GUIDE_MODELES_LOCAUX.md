# ðŸ“± Guide des ModÃ¨les Locaux - RolePlay AI v5.0.0

## ðŸŽ¯ Pourquoi des ModÃ¨les Locaux ?

Les modÃ¨les locaux offrent :
- âœ… **0 latence** - RÃ©ponse instantanÃ©e
- âœ… **0 coÃ»t** - Pas d'API payante
- âœ… **Privacy totale** - Tout reste sur votre tÃ©lÃ©phone
- âœ… **Offline** - Fonctionne sans internet
- âœ… **IllimitÃ©** - Pas de rate limits

---

## ðŸ§  ModÃ¨les RecommandÃ©s

### 1. Gemini Nano (RecommandÃ© #1)

**Le meilleur choix pour Android !**

- **Type** : IA on-device de Google
- **Taille** : IntÃ©grÃ© dans Android 14+
- **QualitÃ©** : â­â­â­â­â­ Excellente
- **Vitesse** : âš¡âš¡âš¡âš¡âš¡ 2-5 secondes
- **Installation** : Automatique

**PrÃ©requis** :
- Android 14 ou supÃ©rieur
- Google Play Services Ã  jour
- Appareil compatible (Pixel 8+, certains Samsung/OnePlus rÃ©cents)

**Activation** :
1. Aller dans ParamÃ¨tres Android
2. Apps > Google > AI Core
3. Activer "Gemini Nano"

**Avantages** :
- QualitÃ© Ã©quivalente Ã  Groq
- TrÃ¨s rapide
- Pas de tÃ©lÃ©chargement manuel
- Support NSFW

---

### 2. Phi-3 Mini 4K (Q4) - RecommandÃ© #2

**Excellent compromis qualitÃ©/taille**

- **Taille** : 2.2 GB
- **QualitÃ©** : â­â­â­â­â­ Excellente
- **Vitesse** : âš¡âš¡âš¡âš¡ 3-8 secondes
- **MÃ©moire** : 4096 tokens de contexte

**TÃ©lÃ©chargement** :
```
https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf
```

**Installation** :
1. TÃ©lÃ©charger le fichier `.gguf`
2. Copier dans : `/sdcard/RolePlayAI/models/`
3. Dans l'app : ParamÃ¨tres > IA Locale > SÃ©lectionner Phi-3

**Pourquoi Phi-3 ?**
- CrÃ©Ã© par Microsoft
- OptimisÃ© pour conversationsroleplay
- Excellente comprÃ©hension du contexte
- Support multilingue (franÃ§ais parfait)
- TrÃ¨s bon en NSFW (naturel)

---

### 3. Gemma 2B (Q4) - LÃ©ger et Rapide

**Pour les appareils avec moins de RAM**

- **Taille** : 1.5 GB
- **QualitÃ©** : â­â­â­â­ TrÃ¨s bonne
- **Vitesse** : âš¡âš¡âš¡âš¡âš¡ 2-5 secondes
- **MÃ©moire** : 2048 tokens de contexte

**TÃ©lÃ©chargement** :
```
https://huggingface.co/google/gemma-2b-it-gguf/resolve/main/gemma-2b-it-q4_k_m.gguf
```

**Installation** :
1. TÃ©lÃ©charger le fichier `.gguf`
2. Copier dans : `/sdcard/RolePlayAI/models/`
3. Dans l'app : ParamÃ¨tres > IA Locale > SÃ©lectionner Gemma

**Pourquoi Gemma ?**
- CrÃ©Ã© par Google
- TrÃ¨s lÃ©ger (fonctionne sur 4GB RAM)
- Rapide
- Bon pour conversations courtes

---

### 4. TinyLlama 1.1B (Q4) - Ultra-LÃ©ger

**Pour les appareils bas de gamme**

- **Taille** : 630 MB
- **QualitÃ©** : â­â­â­ Bonne
- **Vitesse** : âš¡âš¡âš¡âš¡âš¡ 1-3 secondes
- **MÃ©moire** : 2048 tokens de contexte

**TÃ©lÃ©chargement** :
```
https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.q4_k_m.gguf
```

**Installation** :
1. TÃ©lÃ©charger le fichier `.gguf`
2. Copier dans : `/sdcard/RolePlayAI/models/`
3. Dans l'app : ParamÃ¨tres > IA Locale > SÃ©lectionner TinyLlama

**Pourquoi TinyLlama ?**
- TrÃ¨s petit (< 1GB)
- Fonctionne sur 2GB RAM
- Ultra-rapide
- Bon pour texte simple

---

## ðŸ“Š Comparaison

| ModÃ¨le | Taille | RAM Min | Vitesse | QualitÃ© | NSFW | Contexte |
|--------|--------|---------|---------|---------|------|----------|
| **Gemini Nano** | 0 GB | 4 GB | âš¡âš¡âš¡âš¡âš¡ | â­â­â­â­â­ | âœ… | 8K |
| **Phi-3 Mini** | 2.2 GB | 6 GB | âš¡âš¡âš¡âš¡ | â­â­â­â­â­ | âœ… | 4K |
| **Gemma 2B** | 1.5 GB | 4 GB | âš¡âš¡âš¡âš¡âš¡ | â­â­â­â­ | âœ… | 2K |
| **TinyLlama** | 630 MB | 2 GB | âš¡âš¡âš¡âš¡âš¡ | â­â­â­ | âš ï¸  | 2K |

---

## ðŸŽ¯ Quel ModÃ¨le Choisir ?

### Si vous avez Android 14+ (Pixel 8, Samsung S24, etc.)
âž¡ï¸ **Gemini Nano** - Pas de tÃ©lÃ©chargement, qualitÃ© maximale

### Si vous avez un flagship rÃ©cent (8GB+ RAM)
âž¡ï¸ **Phi-3 Mini** - Meilleur compromis qualitÃ©/vitesse

### Si vous avez 4-6GB RAM
âž¡ï¸ **Gemma 2B** - LÃ©ger et rapide

### Si vous avez 2-4GB RAM
âž¡ï¸ **TinyLlama** - Ultra-lÃ©ger

---

## âš™ï¸ Installation DÃ©taillÃ©e

### Ã‰tape 1 : TÃ©lÃ©charger le ModÃ¨le

**Option A : Via navigateur**
1. Cliquer sur le lien de tÃ©lÃ©chargement
2. Attendre la fin (peut prendre 5-30 minutes)
3. Le fichier est dans `/sdcard/Download/`

**Option B : Via termux (plus rapide)**
```bash
pkg install wget
cd /sdcard/RolePlayAI/models/
wget https://huggingface.co/.../model.gguf
```

### Ã‰tape 2 : Placer le ModÃ¨le

1. Ouvrir un gestionnaire de fichiers
2. Aller dans `/sdcard/Download/`
3. CrÃ©er le dossier `/sdcard/RolePlayAI/models/` si inexistant
4. DÃ©placer le fichier `.gguf` dedans

### Ã‰tape 3 : Configurer dans l'App

1. Ouvrir RolePlay AI
2. Menu > ParamÃ¨tres
3. **IA Locale** section
4. "SÃ©lectionner un modÃ¨le local"
5. Choisir le fichier `.gguf`
6. Activer "PrÃ©fÃ©rer IA locale"
7. Sauvegarder

### Ã‰tape 4 : Tester

1. CrÃ©er un nouveau personnage
2. DÃ©sactiver Groq (pour forcer l'IA locale)
3. Envoyer un message
4. Observer les logs :
   ```
   OptimizedLocalLLM: âœ… ModÃ¨le chargÃ©
   AIOrchestrator: âœ… RÃ©ponse gÃ©nÃ©rÃ©e par LLM Local
   ```

---

## ðŸ”§ Optimisation

### Augmenter la Vitesse

**Dans les paramÃ¨tres de l'app** :
- RÃ©duire "Tokens max" Ã  200
- Augmenter "Threads" au nombre de cores CPU
- Activer "Utiliser GPU" si disponible

### Ã‰conomiser la Batterie

- Utiliser TinyLlama pour conversations simples
- DÃ©sactiver GPU si non nÃ©cessaire
- Limiter le contexte Ã  2048 tokens

### AmÃ©liorer la QualitÃ©

- Utiliser Phi-3 Mini ou Gemini Nano
- Augmenter le contexte Ã  4096 tokens
- Temperature Ã  0.85-0.9

---

## ðŸ§  SystÃ¨me de MÃ©moire

**Nouveau dans v5.0.0 !**

Tous les modÃ¨les utilisent maintenant **ConversationMemory** :

âœ… **MÃ©moire Long Terme**
- Sauvegarde de l'historique complet
- Extraction automatique des faits (nom, prÃ©fÃ©rences...)
- RÃ©sumÃ©s tous les 20 messages

âœ… **CohÃ©rence Maximale**
- Niveau de relation (0-100) qui Ã©volue
- Moments clÃ©s sauvegardÃ©s
- Contexte pertinent rÃ©cupÃ©rÃ© automatiquement

âœ… **Immersion Totale**
- Le personnage se souvient de TOUT
- Ã‰volution progressive rÃ©aliste
- Pas de rÃ©pÃ©titions ni incohÃ©rences

**Exemple** :
```
Message 5 : "Je m'appelle Alex"
â†’ MÃ©moire : nom_utilisateur = Alex

Message 50 : "Tu te souviens de mon nom ?"
â†’ RÃ©ponse : "Bien sÃ»r, Alex ! Comment pourrais-je oublier ?"
```

---

## âš ï¸ ProblÃ¨mes Courants

### "ModÃ¨le non chargÃ©"
- VÃ©rifier que le fichier existe dans `/sdcard/RolePlayAI/models/`
- VÃ©rifier l'espace disque (besoin de 2x la taille du modÃ¨le)
- RedÃ©marrer l'application

### "Out of memory"
- Votre appareil n'a pas assez de RAM
- Essayer un modÃ¨le plus petit (Gemma ou TinyLlama)
- Fermer les autres applications

### "GÃ©nÃ©ration trÃ¨s lente"
- Normal au premier lancement (chargement du modÃ¨le)
- VÃ©rifier le nombre de threads (2-4 optimal)
- Essayer un modÃ¨le plus petit

### "RÃ©ponses incohÃ©rentes"
- Le modÃ¨le est trop petit (essayer Phi-3)
- Augmenter le contexte dans les paramÃ¨tres
- VÃ©rifier que ConversationMemory est activÃ©e

---

## ðŸ“ˆ Performances Attendues

### Phi-3 Mini (2.2GB) sur Snapdragon 888

- **Chargement** : 3-5 secondes
- **PremiÃ¨re gÃ©nÃ©ration** : 5-8 secondes
- **GÃ©nÃ©rations suivantes** : 3-5 secondes
- **QualitÃ©** : Ã‰quivalente Ã  GPT-3.5

### Gemini Nano sur Pixel 8

- **Chargement** : InstantanÃ©
- **GÃ©nÃ©ration** : 2-4 secondes
- **QualitÃ©** : Ã‰quivalente Ã  GPT-4

---

## ðŸŽ‰ Avantages de v5.0.0

**Avant (v4.0.0)** :
- Templates fixes
- Pas de mÃ©moire
- IncohÃ©rences

**Maintenant (v5.0.0)** :
- âœ… Vrais LLM locaux (Gemini Nano, Phi-3, etc.)
- âœ… MÃ©moire long terme (RAG)
- âœ… CohÃ©rence maximale
- âœ… 6 niveaux de fallback
- âœ… Offline complet possible

---

## ðŸ“ž Support

**ProblÃ¨me avec un modÃ¨le ?**
1. VÃ©rifier les logs dans l'app (Menu > Logs)
2. Partager le message d'erreur
3. Indiquer votre appareil et modÃ¨le choisi

**Besoin d'aide ?**
- GitHub Issues
- Discord communautaire
- Email support

---

**Profitez de vos conversations avec de vraies IA locales ! ðŸš€**
